---
title: Toolkit
locale: en
publication-date: '2022-10-31'
version: '1.0'
authors:
  - dariah-teach
contributors:
  - dariah-teach
tags:
  - dh
sources:
  - dariah
license: cc-by-4.0
table-of-contents: true
summary:
  content: No summary content available.
content-type: training-module

---

## Toolkit

### Introduction

###### This section is written by Sina Krottmaier and co-designed by Felix Bui.

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/462833e7d64acd92255180b8b6ff3b85d7d7af37-71416.png)The final section of the course, ***The Toolkit***, provides a practical guide to social justice in the digital humanities, offering a range of resources to support your research, including principles, guidelines, and tools, as well as tutorials. These resources aim to help you conduct more open, inclusive, and decolonial research.\
In this section, you will discover a range of tools, tutorials, and resources on diverse facets of Social Justice in the Digital Humanities. These tools are categorized into four thematic areas: Consent and Licenses, Data Ethics, Identity and Accessibility, and Ethical Research Practice. Their purpose is to facilitate effective data management and promote inclusivity and accessibility in research communication and education.

1. **Consent and Licenses**
   * Public License Selector
   * Consent Form Wizard
2. **Data Ethics**
   * Data Ethics Toolkit
   * Ethics and Algorithms Toolkit
   * FAIR Data Maturity Model
3. **Identity and Accessibility**
   * Hemingway Editor
   * RaceWorks Toolkit
   * Mukurtu CMS
4. **Ethical Research Practice**
   * Inclusive Terminology in Technology
   * Decolonizing Research Practices

***

***Author Bio\*:***\
***Sina Krottmaier** is a research assistant at the Centre for Information Modelling – Austrian Centre for Digital Humanities, University of Graz. She is interested in video game studies, 3D modeling and ethical and legal topics relating to the use of tools and data. Her research interests primarily focus on the representation of the past and of different cultures, alternative timelines, and horror in video games.*

****Designer Bio\*:*** **Felix Bui** is currently a junior lecturer at the Faculty of Arts & Social Sciences at Maastricht University. She teaches courses about the history and development of AI, the philosophy of technology, and research skills. She holds a master’s degree in Media Studies: Digital Cultures and a background in Marketing & Communication. Her research interest involves AI and creativity, mediatization and media representation of queer communities, data and media ethics with a focus on diversity and inclusivity.*

*\*Bios and affiliations are accurate at the time of writing.*

### 4.1 Consent and Licenses

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/462833e7d64acd92255180b8b6ff3b85d7d7af37-71415.png)This page of the Tools and Tutorials section of the Toolkit presents two tools that address the issues of *consent* and *licenses* when working with data. The first tool is the **Public License Selector**, which helps researchers and developers choose the most appropriate license for their open-source software and data. It ensures compliance with copyright and other regulations while protecting the rights of authors and users. The second tool is the **Consent Form Wizard**, which helps researchers create GDPR-compliant consent forms (which is most important for those working within the European Union). It simplifies the process and ensures that all necessary information is included, making it easier to obtain informed consent from individuals. Both tools are valuable resources for researchers looking to navigate the legal but also ethical considerations regarding the data of their projects.

###### **Public License Selector**

![cc icons, Cc icons created by iconsax - Flaticon ](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/8683139414e5a6169cec20598e9992f055caf239-71410.png)

*Cc icons created by iconsax - Flaticon*

The Public License Selector is a tool developed by the Institute of Formal and Applied Linguistics at the Faculty of Mathematics and Physics, Charles University in Prague. It is designed to help researchers, developers, and other interested parties easily select the most appropriate license for their work. The tool is designed for open-source software and data subject to copyright and other regulations. It is aimed to help users quickly and easily select the most appropriate license for their work, ensuring that the rights of authors and users of the software and/or data are properly protected. The tool is also useful for ensuring compliance with copyright laws and other regulations. The web-based interface allows users to either search for a specific license or to find a suitable license for their data/software based on a questionnaire. The user can then review the suggested license and make any necessary changes before finalizing their selection. The tool can be implemented in repositories on request and is already used in the CLARIN DSpace repositories and the EUDAT B2SHARE repository.

###### **Why use the tool?**

Open licensing of software and data is often neglected, especially in the academic context. In addition, licenses for data and software have different focuses, which further complicates the choice of an appropriate license. Data licensing deals with the protection of intellectual property and is subject to copyright laws and other regulations, while software licensing deals with the protection of functional products and is not subject to the same level of regulation.

Software licenses tend to focus on issues such as the right to use, modify, and redistribute the software. Data licenses are generally more restrictive and complex than software licenses because they must address issues such as the right to copy, adapt, modify, and distribute the data. Moreover, data licenses often include provisions to protect the data itself, such as restricting access to the data or prohibiting its use for commercial purposes.

The Public License Selector is a useful tool that provides users with an easy way to compare and select the appropriate license for their data or software. It allows users to quickly identify the license that best suits their needs and provides detailed information about the different licenses available, such as the rights and restrictions associated with each license. This can help users avoid potential legal issues by choosing the right license for their data or software. The Public License Selector is also useful for educational purposes.

By providing a simple way for users to choose the most appropriate license for their work, the tool can help raise awareness of copyright and promote the use of open-source software.

\*\*To the tool:**[https://ufal.github.io/public-license-selector/\*\*To](https://ufal.github.io/public-license-selector/**To) the GitHub repository:**

[https://github.com/ufal/public-license-selector\*\*Additional](https://github.com/ufal/public-license-selector**Additional) resource:\*\*

The paper "The Public License Selector: Making Open Licensing Easier" by Pawel Kamocki, Pavel Straňák and Michal Sedlák

###### **Consent Form Wizard**

The ELDAH **Consent Form Wizard** is an online tool developed by the Austrian Centre for Digital Humanities and Cultural Heritage (ACDH-CH) and the Digital Research Infrastructure for the Arts and Humanities (DARIAH-EU) to help researchers working in the European Union create GDPR-compliant consent forms for their research projects, events (such as conferences) or mailing lists. It provides a simple, step-by-step process for creating a consent form tailored to the specific needs of each project and ensures that all the necessary information is included. The tool allows users to choose from several pre-set options, including the type of data to be collected, the purpose of the research, and the duration of the project. It also allows users to add custom information specific to their use case. Once completed, the form can be downloaded as a raw text file and further processed either in a word processor or embedded in a web page. The tool is also available in several languages, making it accessible to a wider range of users.

![Consent Form Wizard Logo ](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/5e10cf8f4e28e39014b41b36372b5e62a5d627d5-71406.svg)

###### **Why using the tool?**

In general, there are certain exemptions from the data protection requirements for research in the General Data Protection Regulation (GDPR). However, there are still certain conditions that must be met for research to be exempt from the GDPR. First, the research must be 'necessary for scientific or historical research purposes' and must be conducted in the public interest. Second, the research must be carried out in accordance with "appropriate safeguards" to protect the rights and freedoms of individuals. This includes ensuring that data is kept secure and that individuals are informed of their rights under the GDPR. In addition, the GDPR also states that any research involving sensitive data, such as health information, must still be subject to the same data protection requirements. This includes obtaining explicit consent from individuals for the collection and processing of their sensitive personal data.

**It should also be noted that although researchers are not required to obtain explicit consent from individuals for the collection, processing, and use of personal data for research purposes that is not sensitive data, it has become a general ethical consensus in scientific practice to obtain informed consent in these cases as well.**

**To the tool:** [https://consent.dariah.eu\*\*Additional](https://consent.dariah.eu**Additional) resource:\*\*

<Embed src="https://www.youtube.com/embed/m_YpSB6Sw08"/>

### 4.2 Data Ethics

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/462833e7d64acd92255180b8b6ff3b85d7d7af37-71415.png)This page of the Tools and Tutorials section of the Toolkit introduces three tools related to data ethics. The first tool is the **Data Ethics Toolkit**, which helps citizen and community science practitioners explore ethical considerations around data. It guides project leaders in identifying ethical issues and incorporating ethical principles into their projects. The second tool is the **Ethics and Algorithms Toolkit**, which helps organizations develop ethical algorithms and assess potential risks and biases. It provides tools and resources throughout the algorithm development lifecycle. The third tool is the **FAIR Data Maturity Model**, which helps to assess how FAIR the research data is by providing indicators and levels of FAIRness. It helps researchers, data publishers, and funding agencies to improve the accessibility and usability of their data. These tools aim to promote the responsible and trustworthy use of data in research projects.

###### **Data Ethics Toolkit**

![Data Ethics Toolkit by Citizen Science Association](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/50c9c382b0810f13cef13f9f1ba8b75d4cb2b0b7-71434.png)

The Data Ethics in the Participatory Sciences Toolkit is a resource created by and for citizen and community science practitioners to explore and identify ethical considerations around data. It has been designed to support the Citizen Science Association's capacity to promote a culture of data ethics in the participatory sciences. The toolkit focuses primarily on project leaders of top-down, institutionally driven projects and considers the obligations between project leaders, participants, and partners. It is designed to support ethical thinking, but with the understanding that a culture of ethical norms is necessary to promote ethical behavior. It guides project leaders to identify ethical issues and obligations and to learn how to use key ethical concepts and principles to make appropriate decisions for their projects. It should be noted that the toolkit is mostly US-focused, so you have to take into consideration that your projects may be subject to laws, regulations, and policies that are not covered in the toolkit.

###### **Why use this tool?**

In general, data ethics is important because it helps ensure data is used responsibly and trustworthy. This includes considering the ethical implications of the collection, storage, and sharing of data and the potential impact of the data on the people who generate or are affected by the data. Data ethics helps to ensure that people's privacy and rights are respected when data is used, and that data is collected and used ethically and responsibly. It also assists in building trust between data users and the people whose data is used, and in ensuring that data is used for the benefit of everyone. The Data Ethics Toolkit is designed to assist you in recognizing and evaluating ethical considerations related to data generated especially by participatory science projects.

Using this toolkit, you will be able to make appropriate decisions for your project by incorporating ethical principles such as respect, reciprocity, transparency, and accountability. It emphasizes two main obligations: to the participants who make the research possible, and to the science itself. This toolkit aims to facilitate data governance that broadens decision-making and meets the needs of both participants and science.

\*\*To the tool:**[https://citizenscience.org/data-ethics/\*\*To](https://citizenscience.org/data-ethics/**To) the tutorial:**

Data Ethics for Practitioners

###### **Ethics and Algorithms Toolkit**

The Ethics & Algorithm Toolkit, developed by the Center of Government Excellence (GovEx) at Johns Hopkins University, DataSF, the Civic Analytics Network at Harvard University, and Data Community DC, is an online platform to help organizations develop ethical algorithms. It provides a comprehensive set of tools, guidelines, resources, and templates to help organizations design, develop, and deploy ethical algorithms. It also entails a risk assessment framework to evaluate the potential for an algorithm to cause harm. The toolkit covers the entire lifecycle of ethical algorithm development and deployment, from initial design to actual implementation. GovEx has worked with leading organizations and experts in the field to ensure that the toolkit is comprehensive and up-to-date with best practices. The toolkit is designed to provide guidance and support to organizations seeking to develop ethical algorithms and help reduce the potential for harm.

![Ethics and Algorithms Toolkit ](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/b23d54af6659789feda7f751ca2c80e867cf45a3-71438.jpg)

###### **Why use this tool?**

Algorithms and AI applications can have biases that lead to injustice and harm. For example, facial recognition algorithms have been found to be less accurate at identifying people from certain racial and ethnic backgrounds, leading to false positives. In addition, algorithms used to predict criminal recidivism are biased against certain racial and ethnic groups. Algorithms used to assess job applicants have also been found to discriminate against women. Thus, to minimize the risks associated with algorithms and AI applications, it is important to ensure that ethical considerations are taken into account in their development and use. This includes conducting a thorough risk assessment, ensuring that data is collected and used responsibly, and regularly testing and monitoring algorithms to ensure that they do not exhibit discriminatory or biased behavior. In addition, organizations should ensure that any decisions made by algorithms and AI applications are accountable and transparent, and that individuals' rights and privacy are respected.

It should also be noted that although researchers are not required to obtain explicit consent from individuals for the collection, processing, and use of personal data for research purposes that is not sensitive data, it has become a general ethical consensus in scientific practice to obtain informed consent in these cases as well. Although initially developed to support local government, the Ethics and Algorithm Toolkit can be adapted for use in the private sector and academia and is, therefore, a useful tool for assessing and minimizing risk when developing and using an algorithm or AI application in your research. On top of that, the Ethics and Algorithms Toolkit is open source and accessible for everyone.

**To the tool:** [https://ethicstoolkit.ai/#toolkit\*\*Additional](https://ethicstoolkit.ai/#toolkit**Additional) resource:\*\*"The promise and peril of algorithms in local government"Interview with Andrew Nicklin and Miriam McKinney of GovEx

###### **FAIR Data Maturity Model**

![Fair Data Maturity Model](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/102f3b4f21aab4c984c5b4308ac5f39f5b77da41-71439.png)

The RDA **FAIR Data Maturity Model** is a set of guidelines developed by the Research Data Alliance Foundation (RDA) to assess the FAIRness of research data by providing indicators, priorities, and maturity levels to measure how FAIR your data resources are. This model can be used by researchers, data publishers, project managers, and funding agencies to determine the level of FAIRness achieved by data resources and to identify where improvements can be made. Application of the model will lead to increased coherence and interoperability of existing or emerging FAIR assessment frameworks and will allow results to be compared in a meaningful way. In addition to the FAIR principles, which are provided in more detail in the "Principles and Guidelines" section of this toolkit, the FAIR Data Maturity Model provides an interactive spreadsheet that you can use to assess the FAIRness of your data easily.

###### **Why use this tool?**

Keeping your data FAIR is very important because it allows data to be used more efficiently and effectively. FAIR data is more accurate, accessible, and reliable, which helps to ensure that data is used in the best possible way. With FAIR data, researchers, organizations, and businesses can make better decisions, gain insights, and create new products and services. FAIR data also helps to foster data sharing and collaboration, which are essential to drive research and innovation.

The tool is based on the four core principles of FAIR (Findable, Accessible, Interoperable, and Reusable) and assigns a level to each principle, ranging from 0 (not applicable) to 4 (fully implemented). To measure progress, each indicator is scored against five levels of compliance (0-4). Alternatively, the pass-or-fail approach measures FAIRness per area, taking into account the priorities, and gives a binary response for each of the indicators, with the level per area determined based on compliance with the priorities. Both approaches can be combined to take advantage of both.

After assigning the appropriate levels to each indicator in the second sheet of the spreadsheet, you will get a detailed graphical report of the FAIRness of your data in the first sheet. This will help you to see if your data is already FAIR or if you need to work on the FAIRness of your data - if possible.

**To the tool:** [https://www.rd-alliance.org/system/files/FAIR\\\_evaluation\\\_levels\\\_v0.01.xlsx\*\*Additional](https://www.rd-alliance.org/system/files/FAIR\\_evaluation\\_levels\\_v0.01.xlsx**Additional) resource:\*\*Webinar "RDA FAIR Data Maturity Model- Aligning International Initiatives for Promoting & Assessing FAIR Data"

<Embed src="https://www.youtube.com/embed/rIMfwu7-hes" />

### 4.3 Identity and Accessibility

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/462833e7d64acd92255180b8b6ff3b85d7d7af37-71415.png)This section of the Toolkit presents three tools related to the topics of identity and accessibility. The first tool is the **Hemingway Editor**, which helps writers improve the clarity and readability of their writing. The second tool is the **RaceWorks Toolkit**, which provides resources and frameworks for having informed conversations about race, racism, and critical race studies. It offers videos, activities, and discussion questions to enhance understanding and navigate discussions about race and racism. The last tool is the **Mukurtu CMS** - a content management system for Indigenous communities to manage and share their digital cultural heritage. All tools aim to promote clearer communication, recognition, and inclusivity in their respective areas of focus.

###### **The Hemingway Editor**

![Hemingway Editor ](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/47e3342792a4688a97d4eb69b06e0c93665d660f-71444.png)

Launched in 2013 by Adam and Ben Long, the Hemingway Editor is an online platform that makes writing bold and clear. It highlights parts of writing that are too dense, allowing readers to focus on the message itself rather than the prose. It also includes the Automated Readability Index to assess the level of writing. The aim is to achieve an average American reading level of tenth grade, but this is not necessarily the target audience. The editor highlights sentences that are difficult to read in yellow and those that are most difficult in red.

###### **Why use this tool?**

When writing, and especially when writing academic texts, writers often forget that not all of their readers may be able to read (sometimes needlessly) complex and intricately structured texts. In this case, the Hemingway Editor can help you write more clearly and concisely. It highlights complex words and offers simpler alternatives. This can make your writing easier to read and more accessible to a wider audience. However, the editor is primarily designed for English texts, especially concerning synonyms for simplification.

The Hemingway Editor is available as a free web application and a paid standalone desktop version (\~$20) for MacOS and Windows.

\*\*To the tool:**[https://hemingwayapp.com/\*\*Additional](https://hemingwayapp.com/**Additional) resource:**

<Embed src="https://www.youtube.com/embed/qvCPuiSxZCk"/>

###### **RaceWorks Toolkit**

RaceWorks is a free online resource created by the Center for Comparative Studies in Race and Ethnicity (CCSRE) at Stanford University and Stanford SPARQ, in collaboration with various scholars and experts. It includes a series of videos, pedagogical activities, discussion questions, and evidence-based frameworks to make critical race studies more accessible to a range of learners and contexts. The toolkit is designed to prepare individuals to have more effective conversations about race, enabling them to better navigate their own communities and the larger world around them. It is free and open to the public.

![Raceworks Toolkit Logo ](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/a38a1e1c16f5170a72115158b92deff0b6515f7f-71450.png)

###### **Why use this tool?**

The toolkit is designed to equip students, professionals, and community advocates with the knowledge and skills necessary to have informed conversations about race and how race and racism impact our world today by providing an evidence-based framework to make critical race studies more accessible. Raceworks offers a 7-step program of informative short videos and teaching materials that can be incorporated into courses and self-study.

The multimedia toolkit provides a research-based model for conversations about race in America today, but because it is designed to apply to a wide range of contexts, it can be used in teaching scenarios around the world (e.g. in academic curricula or professional development opportunities such as diversity, equity and inclusion training).

**To the tool:** [http://sparqtools.org/raceworks/](http://sparqtools.org/raceworks/)

###### **The Mukurtu CMS**

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/0ab5cdd48fa4bab4b06318b55753bfa03c5654fb-71445.png)

Mukurtu (Mook-oo-too) CMS is a content management system designed specifically for Indigenous communities to manage and share their digital cultural heritage. The development of Mukurtu CMS was a collaborative effort between Indigenous communities and a team of researchers, scholars, and technologists and is maintained and further developed by the Mukurtu Team at the Center for Digital Scholarship and Curation at Washington State University.

###### **Why use this tool?**

The platform aims to address the unique cultural protocols, values, and ownership rights associated with Indigenous knowledge and cultural materials and allows Indigenous communities to curate and control access to their digital collections, ensuring that cultural materials are shared in a way that aligns with their cultural practices and values. The system incorporates traditional protocols related to ownership, access, and use of cultural materials, providing a culturally sensitive and respectful approach to managing digital heritage.

The Mukurtu CMS is an open-source platform and is therefore freely available for everyone.

\*\*To the tool:**[https://github.com/MukurtuCMS/mukurtucms\*\*Additional](https://github.com/MukurtuCMS/mukurtucms**Additional) resource:**

<Embed src="https://www.youtube.com/embed/2WRLKw82KGw?si=YBR_iRxXQfr90G-X"/>

### 4.4 Ethical Reseach Practices

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/462833e7d64acd92255180b8b6ff3b85d7d7af37-71415.png)The final page of this section introduces some ethical research practices that are useful in digital scholarship. The first part called **Inclusive Terminology in Technology** includes two different resources, both of which aim to deconstruct the harmful stereotypes perpetuated in the terminology and foster equality and diversity in the field of technology. The second part presents two useful **decolonizing research practices** that researchers can adopt: the 5 key points for decolonizing research methodologies, which the STEPS center incorporated in their research, and the 7-Questions-Model by Mary Shell-Weiss.

###### **Inclusive Terminology in Technology**

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/6731d5f5b16478960a346a54ded2a000af33d77c-71453.png)

**Inclusive Naming Initiative**

The Inclusive Naming Initiative, launched by the Cloud Native Computing Foundation (CNCF) in 2021, aims to incorporate inclusive language across the industry. It was prompted by the increased awareness of diversity issues following the *Black Lives Matter* movement, which also impacted the open-source community. The Initiative's

> mission is to promote and facilitate replacing harmful and exclusionary language in information technology.

Furthermore, the Initiative is working with standards development organizations (e.g. the IEEE) by providing them resources to standardize inclusive terminology in technology worldwide. So far, it has produced useful resources such as word replacement lists, an implementation pathway, and a language framework.

**Toward anti-racist technical Terminology**

"Toward anti-racist technical Terminology", published by The Association for Computers and the Humanities (ACH) and produced by a working group led by CDH lead developer Rebecca Sutton Koeser is a guide to help people in the field of digital humanities to use more inclusive language. The guide is intended to help people understand how language can be used to perpetuate racism and how it can be used to combat it. It provides a set of guidelines for using more inclusive language as well as alternatives for problematic terms in technical writing as well as other forms of communication.

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/94abf4ebc5401ffec39b88c62f7bd92fdb6c490d-71454.jpg)

###### **Why use inclusive terminology?**

Language shapes our worldview and can create and reinforce expectations, stereotypes, and even prejudice, so it is important to take extra care in choosing words and phrases when writing. Metaphors rooted in oppression, ableism, and colonialism are also prevalent in language, particularly in technical communities. Exclusive language can hurt and alienate people, making them feel rejected and not part of a group or team. Terms like "master/slave" are quite obvious in the damage they do by normalizing slavery. Other terms like "blacklist" and "whitelist" may seem less loaded at face value, but they perpetuate the idea that "white" is good and "black" is bad. More often than not, these "metaphors" are not only exclusionary but also unclear in their meaning.

Inclusive terminology, on the other hand, not only promotes equality and diversity in society and the workplace but is often clearer and more precise in its explanatory effect. This should not only be applied to general academic writing but also to coding - as the two examples below confirm.

###### **Decolonizing Research Practices**

**STEPS Centre**

The STEPS Centre (Social, Technological, and Environmental Pathways to Sustainability) was an interdisciplinary research and policy center hosted by the Institute of Development Studies (IDS) and the Science Policy Research Unit (SPRU) at the University of Sussex. The website is still active today. Its mission was to address global challenges related to science, technology, and innovation to promote sustainable development. The center focused on the politics of sustainability transformation, emphasizing the importance of inclusive and democratic processes. From 2018-2021, they actively worked on 4 themes: Transformations, Uncertainty, Nature and Methods. The last theme addresses the question of how to decolonize research.

In their blogpost *'How Do We 'Decolonize' Research Methodologies?'*, they identify 5 entry key points to decolonize their research methods.

![](/assets/content/assets/en/resources/hosted/social-justice-in-the-digital-humanities-toolkit/f8afa4e3928f48d3bbb8f99f6efc772b06fbd186-71455.png)

<H5PWrapper path="social-justice-in-the-digital-humanities/7-question-model-637" />

**The 7-Question Model by Melanie Shell-Weiss**

In the chapter “The Power of Narrative: A Practical Guide to Creating Decolonial, Community-Based Projects”, Melanie Shell-Weiss introduces The 7-Question Model for narrative-based projects that apply feminist and decolonial practices. The model emphasizes the process and purpose of the project, encouraging careful reflection on the intentions, positionality, and roles of all participants. The questions also consider the larger relationships and obligations between participants, both in the present and future. This approach recognizes the importance of collaboration and fosters a deeper understanding of ethics rooted in intercultural dialogue rather than existing boundaries. By engaging in dialog with community partners and collaborators, the researcher/practitioner can navigate the complexities of sharing recorded stories, interviews, and oral histories in a way that respects the involved individuals and their communities. The details and explanation of each question can be found in the full text of the chapter.

###### **Why does decolonizing research matter?**

Decolonizing research involves challenging the North's dominant position in knowledge production. In the realm of research, this entails employing approaches that capture the local context and give priority to the needs, experiences, and beliefs of the research participants. The goal of decolonized research is to challenge the cognitive injustice in knowledge production by valuing local culture and knowledge. It aims to amplify indigenous voices and narratives and promote culturally sensitive knowledge production that originates from the community itself rather than being about the community. Furthermore, northern-oriented research practices tend to overlook the unique experiences and perspectives of people in the global South, leaving a considerable part of human history and narratives disregarded.
