---
title: Analyzing Multilingual French and Russian Text using NLTK, spaCy, and Stanza
locale: en
publication-date: 2025-01-30
version: 1.0.0
authors:
  - goodale-ian
editors:
  - chapot-laura-alice
contributors: []
tags:
  - python
  - data-management
sources:
  - programming-historian
featured-image: /assets/content/assets/en/resources/external/analyzing-multilingual-french-and-russian-text-using-nltk-spacy-and-stanza/featured-image.png
license: cc-by-4.0
table-of-contents: false
summary:
  content: This lesson covers tokenization, part-of-speech tagging, and
    lemmatization, as well as automatic language detection, for non-English and
    multilingual text. You'll learn how to use the Python packages NLTK, spaCy,
    and Stanza to analyze a multilingual Russian and French text.
content-type: training-module
remote:
  publication-date: 2024-11-13
  url: https://doi.org/10.46430/phen0121
  publisher: ProgHist Ltd
doi: https://hdl.handle.net/21.11159/019595c4-2bd8-748d-8cea-4cd9d770b7b6
---
Many of the resources available for learning computational methods of text analysis focus on English-language texts and corpora, and often lack the information which is needed to work with non-English source material. To help remedy this, this lesson will provide an introduction to analyzing non-English and multilingual text (that is, text written in more than one language) using Python. Using a multilingual text composed of Russian and French, this lesson will show how you can use computational methods to perform three fundamental preprocessing tasks: tokenization, part-of-speech tagging, and lemmatization. Then, it will teach you to automatically detect the languages present in a preprocessed text.

To perform the three fundamental preprocessing steps, this lesson uses three common Python packages for Natural Language Processing (NLP): the Natural Language Toolkit (NLTK), spaCy, and Stanza. We'll start by going over these packages, reviewing and comparing their core features, so you can understand how they work and discern which tool is right for your specific use case and coding style.

#### Reviewed by:

* William Mattingly
* Merve Tekg√ºrler

## Learning outcomes

After completing this lesson, you will be able to:

* Gain some strategies for analyzing non-English, multilingual text
* Use computational methods to perform three fundamental preprocessing tasks: tokenization, part-of-speech tagging, and lemmatization
* Automatically detect the languages present in a preprocessed text

<ExternalResource title="Interested in learning more?" subtitle="Check out this lesson on Programming Historian's website" url="https://doi.org/10.46430/phen0121" />
