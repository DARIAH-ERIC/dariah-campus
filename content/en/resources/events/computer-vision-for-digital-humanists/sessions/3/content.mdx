This practical session encompasses three videos that guide participants
through data preparation and building computer vision models, ranging from
basic to large-scale analysis.

<Video provider="youtube" id="https://www.youtube.com/watch?v=FIA7HTzvWB8&list=PLWNohMNguM_nO3SG9UrzPpbybV_UoCg5w&index=5">

</Video>

The first video, "Get the Data," led by Suzana Sagadin, teaches how to create a corpus using the Python Pandas library. Accompanying this session is a blog post by Sagadinand Sarah Lang that discusses forming humanities research questions suitable for computer vision and selecting a dataset that can be used to train a computer vision algorithm for solving this particular issue. Using the example of classifying photos from the 19th or 20th century illustrates the complexity hidden in seemingly simple research questions in the context of Humanities data.

<Link link={{"discriminant":"external","value":"https://latex-ninja.com/2023/07/04/how-to-create-a-ground-truth-data-set-for-computer-vision-using-humanities-data/"}}>Suzana Sagadin & Sarah Lang, How to create a ground truth data set for computer vision using Humanities data, in LaTeX Ninja Blog, 04.07.2023.</Link>

The second video, "The Mini Model," shows how to prepare data for a “Hello World!” deep learning model in Python. This includes organizing data, preprocessing, and model construction. The video fills in these details often omitted in standard tutorials, ensuring a thorough understanding necessary for training custom algorithms using one's own data.

<Video provider="youtube" id="https://www.youtube.com/watch?v=XVk0VAU6udQ&list=PLWNohMNguM_nO3SG9UrzPpbybV_UoCg5w&index=6">

</Video>

The third video, "The Large Model," extends the concepts from the earlier sessions to a more complex model, suitable for real-world applications. It also shows how to use TensorBoard for monitoring and evaluating machine learning progress.

<Video provider="youtube" id="https://www.youtube.com/watch?v=JT24UNFnpSk&list=PLWNohMNguM_nO3SG9UrzPpbybV_UoCg5w&index=9">

</Video>

These sessions are conducted in Google Colab using Jupyter notebooks, a user-friendly format ideal for those with limited technical skills or Python experience. Participants have the option to use Google Colab or work with provided code and datasets locally on their machine. The code notebooks have been archived on Zenodo where they will remain accessible.

<Link link={{"discriminant":"external","value":"https://zenodo.org/records/10376518"}}>Code notebooks on Zenodo</Link>

<Video provider="youtube" id="https://www.youtube.com/playlist?list=PLWNohMNguM_nO3SG9UrzPpbybV_UoCg5w">

</Video>
