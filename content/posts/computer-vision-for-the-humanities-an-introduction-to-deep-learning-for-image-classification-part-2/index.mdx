---
title: "Computer Vision for the Humanities: An Introduction to Deep Learning for
  Image Classification (Part 2)"
lang: en
date: 2024-02-06T12:04:57.460Z
version: 1.0.0
authors:
  - van-strien-daniel
  - beelen-kaspar
  - wevers-melvin
  - smits-thomas
  - mcdonough-katherine
editors:
  - siddiqui-nabeel
  - wermer-colan-alex
contributors: []
tags:
  - python
  - machine-learning
categories:
  - programming-historian
featuredImage: images/computer-vision-deep-learning-pt2-original-large-greyscale.png
abstract: This is the second of a two-part lesson introducing deep learning
  based computer vision methods for humanities research. This lesson digs deeper
  into the details of training a deep learning based computer vision model. It
  covers some challenges one may face due to the training data used and the
  importance of choosing an appropriate metric for your model. It presents some
  methods for evaluating the performance of a model.
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: 2022-08-17T00:00:00.000Z
  url: https://doi.org/10.46430/phen0102
  publisher: ProgHist Ltd
licence: ccby-4.0
toc: false
draft: false
uuid: _prj5eNH91pvpYlSod2f4
---
Over the last ten years, the field of computer vision, which seeks to gain a high-level understanding of images using computational techniques, has seen rapid innovation. For example, computer vision models can locate and identify people, animals and thousands of objects included in images with high accuracy. This technological advancement promises to do the same for image recognition that the combination of OCR/NLP techniques has done for texts. Put simply, computer vision opens up a part of the digital archive for large-scale analysis that has remained mostly unexplored: the millions of images in digitised books, newspapers, periodicals, and historical documents. Consequently, historians will now be able to explore the ‘visual side of the digital turn in historical research’.[](https://programminghistorian.org/en/lessons/computer-vision-deep-learning-pt1#fn:3)

This two-part lesson provides examples of how computer vision techniques can be applied to analyse large historical visual corpora in new ways and how to train custom computer vision models. As well as identifying the contents of images and classifying them according to category — two tasks which focus on visual features — computer vision techniques can also be used to chart the stylistic (dis)similarities between images.

A particular focus of this lesson will be on how the fuzziness of concepts can translate (or fail to translate) into machine learning models. Using machine learning for research tasks will involve mapping messy and complex categories and concepts onto a set of labels that can be used to train machine learning models. This process can cause challenges, some of which we’ll touch on during this lesson.

Reviewed by:
- Michael Black
- Catherine DeRose

## Learning outcomes

After completing this lesson, you will be able to:

- Interpret what different metrics mean about your model's performance, and to identify where it is performing poorly
- Use data augmentation as a tool for reducing the amount of training data needed to train a machine learning model.
- Understand the complexity of mapping complex or fuzzy concepts onto set categories

<ExternalResource title="Interested in learning more?" subtitle="Check out this lesson on Programming Historian's website" url="https://doi.org/10.46430/phen0102" />
