---
title: Modeling Dictionaries in OntoLex-Lemon
lang: en
date: 2022-01-02T13:29:45.624Z
version: 1.0.0
authors:
  - mccrae-john
  - khan-fahad
tags:
  - lexicography
abstract: This course describes the OntoLex-Lemon model, a recent standard for
  the representation of lexical information on the Web as linked data.
domain: Social Sciences and Humanities
targetGroup: Domain researchers
type: training-module
remote:
  date: ""
licence: ccby-4.0
toc: true
uuid: XUpXflNpQ08j3hdNp7pSi
categories:
  - dariah
---
This course describes the OntoLex-Lemon model, a recent standard for the representation of lexical information on the Web as linked data. In addition to providing a basic introduction to linked data and the Resource Description Framework (RDF), the course will cover the core model of OntoLex and how to represent basic lexical information. Additional modules of the OntoLex module for the description of syntax, term decomposition, variation & translation, metadata, lexicography, morphology and corpus information will also be described. At the end of the course, students should be able to express lexicons as linked data using the model.

## Learning Outcomes

Upon completion of this course, students will be able to

- Understand how lexical data can be represented as linked data
- Describe the benefits of linked data for lexicography
- Use the OntoLex-Lemon module to model lexical information
- Design a schema based on OntoLex-Lemon to represent a specific lexical resource

# Introduction

OntoLex-lemon is a vocabulary developed by the [OntoLex Community Group](https://www.w3.org/community/ontolex/) of the W3C for the representation of dictionaries as [RDF](https://www.w3.org/RDF/) data. The model has a modular architecture which means that you can select the modules which are relevant to your specific data. The original design goals of the model were also focused on the development of lexical information for ontologies, however modules have been developed to represent all kinds of lexical resources. This course assumes some familiarity with RDF, in particular in the Turtle syntax, for those unfamiliar with this we suggest that you look at the primer here: https://www.w3.org/2007/02/turtle/primer/

## History of the model

![](images/introduction-to-the-ontolex-lemon-model.png "Timeline of the development of the OntoLex-Lemon model")

The model has been developed over a long period and originates with three models that were developed independently, the [LingInfo](http://lrec.elra.info/proceedings/lrec2006/workshops/W14/Ontolex06.pdf#page=32) model developed by Paul Buitelaar, the [LexOnto](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.73.1056&rep=rep1&type=pdf) model developed by Philipp Cimiano and the[ Linguistic Information Repository (LIR) ](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/BBB120E33DBD895791136BDB61A8A228/S1351324910000082a.pdf/enriching-ontologies-with-multilingual-information.pdf)developed by Elena Montiel and colleagues. Realising the common overlap of these models, these researchers came together to develop first the [LexInfo](https://lexinfo.net/) model and the _[lemon](https://lemon-model.net/)_ (Lexicon Model for Ontologies) models. The model was then opened to a wider community by means of the founding of the community group, which developed the first version of the model, with the final specification being released in 2016 and a further module focused on representing lexicographic resources was released in 2019.

## Model Requirements

When the OntoLex-lemon model was first developed the following requirements were seen as key goals of the model

1. **OWL and RDF Model:** The goal of the model was to develop a model for the Semantic Web, built on the standards developed by the W3C. As such, the model can take advantage of the powerful formalisms for the representation of knowledge graphs, including the use of URIs to ensure global uniqueness of identifiers, and the powerful reasoning facilities provided by OWL
2. **Multilingualism:** The second key requirement was that the model should aim to support lexicography in all languages and in particular we wanted to avoid making any specific restrictions such as the number of part-of-speech values or specific issues like gender, which may be difficult to apply to other languages.
3. **Semantics by Reference:** Meaning in this model should be represented by means of reference to ontologies, ensuring the representation methods from knowledge graphs, in particular OWL, can be used to represent the semantics. As such, this means that senses in an OntoLex-lemon model are defined by the elements in the ontology they refer to.
4. **Openness:** The OntoLex-lemon model is an open model in several senses. Firstly, it is free both in the sense that there are no finanical costs associated with any documentation of the model (free as in 'free beer') but also free to be extended and worked with (free as in 'free speech'). Further, the community group is open to anyone and all discussions on mailing lists are openly available on the web.
5. **Reuse standards:** The model should wherever possible reuse vocabulary and modelling from standards in order to avoid reinventing the wheel. In particular, we are reusing models such as OWL, RDF, SKOS, Dublin Core, the Lexical Markup Framework (LMF) and the Terminological Markup Framework.

# The Model

The OntoLex-lemon model was introduced due to the observation that ontologies contain very little information about how words are represented in natural language. The basic model of OWL allows for a linguistic label to be added to a ontology entity with a language tag given by the BCP-74 standard, for example we can describe the concept [Q315](https://www.wikidata.org/wiki/Q315) in the Wikidata as follows:

```
<https://www.wikidata.org/wiki/Q315> rdfs:label "language"@en ,
  "Sprache"@de, "teanga"@ga, "言語"@ja .
```

However, this representation is very limited and does not cover how the label is used in real language. For example, the Irish term "teanga" may appear in a very different form such as in "Cuairt Liteartha do **Theangacha** Mionlaigh san Eoraip" (Literary tour of minority languages in Europe), which would be very difficult to identify from the lemma alone, and other key information such as readings of the Japanese lemma cannot easily be represented.

Another issue is the large number of synonyms that exist for many terms both in language and in ontologies. For example, the term "edema" is a medical condition that can be represented by many identifiers for example Q152234 in Wikidata, D00487 in the Medical Subject Headings (MeSH), C0013604 in the Unified Medical Language System (UMLS) and R60.9 in the International Classification of Diseases (ICD). Moreover, we may have several terms that can be used to refer to this, including the irregular plural form "edemata" and alternative terms such as "dropsy". Linking all of these together could be very complex as shown in the image below:

![](images/edema_messy.png "Modelling links between knowledge graphs and lexical information can lead to many links between the concepts")